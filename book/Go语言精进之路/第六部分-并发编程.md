# 并发编程

## 31 优先考虑并发设计

> 并发不是并行，并发关乎结构，并行关乎执行。——Rob Pike，Go 语言之父

要想充分利用多核的强大计算能力，一般有两种方案：

- **并行**方案：在处理器核数充足的情况下启动多个单线程应用的实例，这样每个实例“运行”在一个核上，尽可能多地利用多核计算资源。
- **并发**方案：并发就是重新做应用结构设计，即将应用分解成多个在基本执行单元中执行的，可能有一定关联关系的代码片段。

Go 语言的设计哲学之一是“原生并发，轻量高效”。Go 并未使用操作系统线程作为承载分解后的代码片段的基本执行单元，而是实现了 goroutine 这一**由 Go 运行时负责调度的用户层轻量级线程**为并发程序设计提供原生支持。goroutine 相比传统操作系统线程而言具有如下优势：

- 资源占用小，每个 goroutine 的初始栈大小仅为 2KB；
- 由 Go 运行时而不是操作系统调度，goroutine 上下文切换代价较小；
- 语言原生支持：goroutine 由 go 关键字接函数或方法创建，函数或方法返回即表示 goroutine 退出，开发体验更佳；
- 语言内置 channel 作为 goroutine 间通信原语，为并发设计提供强大支撑。

Go 语言是面向并发而生的。因此，在应用的结构设计阶段，**Go 的惯例是优先考虑并发设计**。这样做更多是考虑到随着外界环境的变化，经过并发设计的 Go 应用可以更好、更自然地适应**规模化**。

案例-模拟机场安检：

- [顺序设计](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/concurrency-design-airport-securitycheck-1.go)
- [并行方案](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/concurrency-design-airport-securitycheck-2.go)
- [并发方案](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/concurrency-design-airport-securitycheck-3.go)

```GO
const (
   idCheckTmCost   = 60
   bodyCheckTmCost = 120
   xRayCheckTmCost = 180
)

func idCheck(id string) int {
   time.Sleep(time.Millisecond * time.Duration(idCheckTmCost))
   print("\tgoroutine-", id, "-idCheck: idCheck ok\n")
   return idCheckTmCost
}

func bodyCheck(id string) int {
   time.Sleep(time.Millisecond * time.Duration(bodyCheckTmCost))
   print("\tgoroutine-", id, "-bodyCheck: bodyCheck ok\n")
   return bodyCheckTmCost
}

func xRayCheck(id string) int {
   time.Sleep(time.Millisecond * time.Duration(xRayCheckTmCost))
   print("\tgoroutine-", id, "-xRayCheck: xRayCheck ok\n")
   return xRayCheckTmCost
}

func start(id string, f func(string) int, next chan<- struct{}) (chan<- struct{}, chan<- struct{}, <-chan int) {
   queue := make(chan struct{}, 10)
   quit := make(chan struct{})
   result := make(chan int)

   go func() {
      total := 0
      for {
         select {
         case <-quit:
            result <- total
            return
         case v := <-queue:
            total += f(id)
            if next != nil {
               next <- v
            }
         }
      }

   }()
   return queue, quit, result
}

func newAirportSecurityCheckChannel(id string, queue <-chan struct{}) {
   go func(id string) {
      print("goroutine-", id, ": airportSecurityCheckChannel is ready...\n")
      // start xRayCheck routine
      queue3, quit3, result3 := start(id, xRayCheck, nil)

      // start bodyCheck routine
      queue2, quit2, result2 := start(id, bodyCheck, queue3)

      // start idCheck routine
      queue1, quit1, result1 := start(id, idCheck, queue2)

      for {
         select {
         case v, ok := <-queue:
            if !ok {
               close(quit1)
               close(quit2)
               close(quit3)
               total := max(<-result1, <-result2, <-result3)
               print("goroutine-", id, ": airportSecurityCheckChannel time cost:", total, "\n")
               print("goroutine-", id, ": airportSecurityCheckChannel closed\n")
               return
            }
            queue1 <- v
         }
      }
   }(id)
}

func max(args ...int) int {
   n := 0
   for _, v := range args {
      if v > n {
         n = v
      }
   }
   return n
}

func main() {
   passengers := 30
   queue := make(chan struct{}, 30)
   newAirportSecurityCheckChannel("channel1", queue)
   newAirportSecurityCheckChannel("channel2", queue)
   newAirportSecurityCheckChannel("channel3", queue)

   time.Sleep(5 * time.Second) // 保证上述三个goroutine都已经处于ready状态
   for i := 0; i < passengers; i++ {
      queue <- struct{}{}
   }
   time.Sleep(5 * time.Second)
   close(queue) // 为了打印各通道的处理时长
   time.Sleep(1000 * time.Second)
}
```

## 32 了解 goroutine 的调度原理

由于一个 goroutine 占用资源很少，一个 Go 程序中可以创建成千上万个并发的 goroutine。而将这些 goroutine 按照一定算法放到 CPU 上执行的程序就称为 **goroutine 调度器**。一个 Go 程序对于操作系统来说只是一个**用户层程序**，操作系统眼中只有线程，goroutine 的调度全要靠 Go 自己完成。

### goroutine 调度模型与演进过程

- **G-M 模型**：Go1.0 实现了一个简单的 goroutine 调度器。在这个调度器中，每个 goroutine 对应于运行时中的一个抽象结构——G (goroutine)，而被视作“物理 CPU”的操作系统线程则被抽象为另一个结构——M (machine)。重要不足：限制了 Go 并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。问题主要体现在：
  - 单一全局互斥锁和集中状态存储的存在导致所有 goroutine 导致所有 goroutine 相关操作（如创建、重新调度）都要上锁；
  - goroutine 传递问题：经常在 M 之间传递“可运行”的 goroutine 会导致调度延迟增大，带来额外的性能损耗；
  - 每个 M 都做内存缓存，导致内存占用过高，数据局部性较差；
  - 因系统调用而形成的频繁的工作线程阻塞和解除阻塞会带来额外的性能损耗。
- **G-P-M 模型**：Dmitry Vyukov 在 Go1.1 实现了 **G-P-M 调度模型**和 **work stealing 算法**，这个模型一直沿用至今。有人曾说过：“**计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。**”P 是一个“逻辑处理器”，每个 G 要想真正运行起来，首先需要被分配一个 P，即进入 P 的本地运行队列中，这里暂忽略全局运行队列那个环节。对于 G 来说，P 就是运行它的 CPU，可以说**在 G 的眼里只有 P**。但从 goroutine 调度器的视角来看，真正的 CPU 是 M，只有将 P 和 M 绑定才能让 P 的本地运行队列中的 G 真正运行起来。
- **抢占式调度**：G-P-M 模型不支持抢占式调度，这导致一旦某个 G 中出现死循环的代码逻辑，那么 G 将永久占用分配给它的 P 和 M，而位于同一个 P 中的其他 G 将得不到调度，出现“**饿死**”的情况。更为严重的是：当只有一个 P (GOMAXPROCS=1) 时，整个 Go 程序中的其他 G 都将“饿死”。于是 Dmitry Vyukov 又提出了“Go 抢占式调度器设计”，并在 Go1.2 版本中实现了抢占式调度。这个抢占式调度的原理是**在每个函数或方法的入口加上一段额外的代码，让运行时有机会检查是否需要执行抢占调度**。这种**协作式抢占调度**的解决方案只是局部解决了“饿死”问题，对于没有函数调用而是纯算法循环计算的 G，goroutine 调度器依然无法抢占。Go1.14 版本中加入了基于系统信号的 goroutine 抢占式调度机制，很大程度上解决了 goroutine “饿死”的问题。
- **NUMA 调度模型**：在 Go1.2 以后，Go 将重点放在了对 GC 低延迟的优化上，对调度器的优化和改进似乎不那么热心了，只是伴随着 GC 的改进而作了些小的改动。Dmitry Vyukov 在 2014 年 9 月提出了一个新的设计草案文档“NUMA - aware scheduler for Go”，作为对未来 goroutine 调度器演进方向的一个提案，不过这个提案至今也没有被列入开发计划。
- **其他优化**：Go 运行时已经实现了 **netpoller**，这使得即便 G 发起网络 I/O 操作也不会导致 M 被阻塞（仅阻塞 G），因而不会导致大量线程（M）被创建出来。但是对于常规文件的 I/O 操作一旦阻塞，那么线程（M）将进入挂起状态，等待 I/O 返回后被唤醒。这种情况下 P 将与挂起的 M 分离，再选择一个处于空闲状态（idle）的 M。如果此时没有空闲的 M，则会新创建一个 M（线程），这就是大量文件 I/O 操作会导致大量线程被创建的原因。Ian Lance Taylor 在 Go1.9 版本中增加了一个针对文件 I/O 的 **Poller**，它可以像 netpoller 那样，在 G 操作那些支持监听的（pollable）文件描述符时，仅阻塞 G，而不会阻塞 M。不过该功能依然对常规文件无效，常规文件是不支持监听的。但对于 goroutine 调度器而言，这也算是一个不小的进步了。

### goroutine 调度器原理的进一步理解

**G、P、M**：

- G：代表 goroutine，存储了 goroutine 的执行栈信息、goroutine 状态及 goroutine 的任务函数等。另外 G 对象是可以重用的；
- P：代表逻辑 processor，P 的数量决定了系统内最大可并行的 G 的数量（前提：系统的物理 CPU 核数 >= P 的数量）。P 中最有用的是其拥有的各种 G 对象队列、链表、一些缓存和状态；
- M：代表着真正的执行计算资源。在绑定有效的 P 后，进入一个调度循环；而调度循环的机制大致是从各种队列、P 的本地运行队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M。如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。

**G 被抢占调度**：Go 中没有时间片的概念。如果某个 G 没有进行系统调用、没有进行 I/O 操作、没有阻塞在一个 channel 操作上，那么 G 将被抢占调度。在 Go 程序启动时，运行时会启动一个名为 sysmon 的 M（一般称为监控线程），该 M 的特殊之处在于它无需绑定 P 即可运行。该 M 在整个 Go 程序的运行过程中至关重要，sysmon 每 20us ~ 10ms 启动一次，主要完成如下工作：

- 释放闲置超过 5 min 的 span 物理内存；
- 如果超过 2 分钟没有垃圾回收，强制执行；
- 将长时间未处理的 netpoll 结果添加到任务队列；
- 向长时间运行的 G 任务发出抢占调度；
- 收回因 syscall 长时间阻塞的 P。

**channel 阻塞或网络 I/O 情况下的调度**：如果 G 被阻塞在某个 channel 操作或网络 I/O 操作上，那么 G 会被放置到某个等待队列中，而 M 会尝试运行 P 的下一个可运行的 G。如果此时 P 没有可运行的 G 供 M 运行，那么 M 将解绑 P，并进入挂起状态。当 I/O 操作完成或 channel 操作完成，在等待队列中的 G 会被唤醒，标记为 runnable（可运行），并被放入某个 P 的队列中，绑定一个 M 后继续执行。

**系统调用阻塞情况下的调度**：如果 G 被阻塞在某个系统调用上，那么不仅 G 会阻塞，执行该 G 的 M 也会解绑 P（实质是被 sysmon 抢走了），与 G 一起进入阻塞状态。如果此时有空闲的 M，则 P 会与其绑定并继续执行其他 G；如果没有空闲的 M，但仍然有其他 G 要执行，那么就会创建一个新 M（线程）。当系统调用返回后，阻塞在该系统调用上的 G 会尝试获取一个可用的 P，如果有可用 P，之前运行该 G 的 M 将绑定 P 继续运行 G；如果没有可用的 P，那么 G 与 M 之间的关联将解除，同时 G 会被标记为 runnable，放入全局的运行队列中，等待调度器的再次调度。

## 33 掌握 Go 并发模型和常见并发模式

> 不要通过共享内存来通信，而应该通过通信来共享内存。——Rob Pike，Go 语言之父

### Go 并发模型

Go 在新并发模型设计中借鉴了 Tony Hoare 提出的 **CSP** (Communicating Sequential Process，通信顺序进程)，旨在简化并发程序的编写，让并发程序的编写和编写顺序程序一样简单。他认为输入/输出应该是基本的编程原语，数据处理逻辑 (CSP 中的 P) 仅需调用输入原语获取数据，顺序处理数据，并将结果数据通过输出原语输出即可。

为了实现 CSP 模型中的输入/输出原语，Go 引入了 **goroutine (P)** 之间的通信原语 **channel**。goroutine 可以从 channel 获取输入数据，在将处理后得到的结果数据通过 channel 输出。通过 channel 将 goroutine (P) 组合与连接在一起，这使得设计和编写大型并发系统变得更为简单和清晰。Go 也支持传统的**基于共享内存的并发模型**，并提供基本的低级同步原语（主要是 sync 包中的互斥锁、条件变量、读写锁、原子操作等）。

实践中选择 channel 还是在低级同步原语保护下的共享内存呢？从程序的整体结构来看，**Go 始终推荐以 CSP 模型风格构建并发程序**，尤其是在复杂的业务层面。这将提升程序逻辑的清晰度，大大降低并发设计的复杂性，并让程序更具可读性和可维护性；对于局部情况，比如涉及性能敏感的区域或需要保护的结构体数据，可以使用更为高效地低级同步原语（如 sync、Mutex），以保证 goroutine 对数据的同步访问。

### Go 常见的并发模式

 Go 针对 CSP 模型提供了三种并发原语：

- **goroutine**：对应 CSP 模型中的 **P**，封装了数据的处理逻辑，是 Go 运行时调度的基本执行单元；
- **channel**：对应 CSP 模型中的**输入/输出**原语，用于 goroutine 之间的**通信**和**同步**；
- **select**：用于应对**多路**输入/输出，可以让 goroutine 同时**协调处理**多个 channel 操作。

实践中这些原语的常见组合方式——并发模式：创建模式、退出模式、管道模式、超时与取消模式。

### 创建模式

Go 语言使用 `go 关键字 + 函数/方法`创建 goroutine，在稍复杂一些的并发程序中，需要考虑通过 CSP 模型输入/输出原语的承载体 channel 在 goroutine 之间建立**联系**。下面方式**在内部创建一个 goroutine 并返回一个 channel 类型变量的函数**，这是 Go 最常见的 goroutine 创建模式。spawn 函数创建的新 goroutine 与调用 spawn 函数的 goroutine 之间通过一个 channel 建立起了连接：两个 goroutine 可以通过这个 channel 进行**通信**。spawn 函数的实现得益于 channel 作为 Go 语言**一等公民**（first-class citizen）的存在：channel 可以像变量一样被初始化、传递和赋值。

```Go
type T struct {...}

func spawn(f func()) chan T {
    c := make(chan T)
    go func() {
        // 使用 channel 变量 c（通过闭包方式）与调用 spawn 的 goroutine 通信
        ...
        f()
        ...
    }()
    return c
}

func main() {
    c := spawn(func(){})
    // 使用 channel 变量 c 与新创建的 goroutien 通信
}
```

### 退出模式

goroutine 的使用代价很低，在多数情况下，我们无须考虑对 goroutine 的退出进行控制：goroutine 的执行函数返回，即意味着 goroutine 退出。但一些常驻的后台服务程序可能会对 goroutine 有着优雅退出的要求。goroutine 的几种退出模式：

1. 分离（detached）模式：使用最广泛的 goroutine 退出模式。对于分离的 goroutine，创建它的 goroutine 不需要关心它的退出，这类 goroutine 在启动后即与其创建者彻底分离，其生命周期与其执行的主函数相关，函数返回即 goroutine 退出。

   - 一次性任务：新创建的 goroutine 用来执行一个简单的任务，执行后即退出。
   - 常驻后台执行一些特定任务，如监视（monitor）、观察（watch）等。其实现通常采用 for{...} 或 for{ select{...} } 代码段形式，并多以定时器（timer）或事件（event）驱动执行。

2. join 模式：goroutine 的创建者需要等待新 goroutine 结束。

   - 等待一个 goroutine 退出；

     ```Go
     func worker(args ...interface{}) {
        if len(args) == 0 {
           return
        }
        interval, ok := args[0].(int)
        if !ok {
           return
        }
     
        time.Sleep(time.Second * (time.Duration(interval)))
     }
     
     func spawn(f func(args ...interface{}), args ...interface{}) chan struct{} {
        c := make(chan struct{})
        go func() {
           f(args...)
           c <- struct{}{}
        }()
        return c
     }
     
     func main() {
        done := spawn(worker, 5)
        println("spawn a worker goroutine")
        <-done
        println("worker done")
     }
     ```

   - 获取 goroutine 的退出状态；

     ```Go
     var OK = errors.New("ok")
     
     func worker(args ...interface{}) error {
        if len(args) == 0 {
           return errors.New("invalid args")
        }
        interval, ok := args[0].(int)
        if !ok {
           return errors.New("invalid interval arg")
        }
     
        time.Sleep(time.Second * (time.Duration(interval)))
        return OK
     }
     
     func spawn(f func(args ...interface{}) error, args ...interface{}) chan error {
        c := make(chan error)
        go func() {
           c <- f(args...)
        }()
        return c
     }
     
     func main() {
        done := spawn(worker, 5)
        println("spawn worker1")
        err := <-done
        fmt.Println("worker1 done:", err)
        done = spawn(worker)
        println("spawn worker2")
        err = <-done
        fmt.Println("worker2 done:", err)
     }
     ```

   - 等待多个 goroutine 退出；

     ```Go
     func worker(args ...interface{}) {
        if len(args) == 0 {
           return
        }
     
        interval, ok := args[0].(int)
        if !ok {
           return
        }
     
        time.Sleep(time.Second * (time.Duration(interval)))
     }
     
     func spawnGroup(n int, f func(args ...interface{}), args ...interface{}) chan struct{} {
        c := make(chan struct{})
        var wg sync.WaitGroup
     
        for i := 0; i < n; i++ {
           wg.Add(1)
           go func(i int) {
              name := fmt.Sprintf("worker-%d:", i)
              f(args...)
              println(name, "done")
              wg.Done() // worker done!
           }(i)
        }
     
        go func() {
           wg.Wait()
           c <- struct{}{}
        }()
     
        return c
     }
     
     func main() {
        done := spawnGroup(5, worker, 3)
        println("spawn a group of workers")
        <-done
        println("group workers done")
     }
     ```

   - 支持超时机制的等待。

     ```Go
     func main() {
        done := spawnGroup(5, worker, 30)
        println("spawn a group of workers")
     
        timer := time.NewTimer(time.Second * 5)
        defer timer.Stop()
        select {
        case <-timer.C:
           println("wait group workers exit timeout!")
        case <-done:
           println("group workers done")
        }
     }
     ```

3. notify-and-wait 模式

   - 通知并等待一个 goroutine 退出

     ```Go
     func worker(j int) {
        time.Sleep(time.Second * (time.Duration(j)))
     }
     
     func spawn(f func(int)) chan string {
        quit := make(chan string)
        go func() {
           var job chan int // 模拟job channel
           for {
              select {
              case j := <-job:
                 f(j)
              case <-quit:
                 quit <- "ok"
              }
           }
        }()
        return quit
     }
     
     func main() {
        quit := spawn(worker)
        println("spawn a worker goroutine")
     
        time.Sleep(5 * time.Second)
     
        // notify the child goroutine to exit
        println("notify the worker to exit...")
        quit <- "exit"
     
        timer := time.NewTimer(time.Second * 10)
        defer timer.Stop()
        select {
        case status := <-quit:
           println("worker done:", status)
        case <-timer.C:
           println("wait worker exit timeout")
        }
     }
     ```

   - 通知并等待多个 goroutine 退出

     ```Go
     func worker(j int) {
        time.Sleep(time.Second * (time.Duration(j)))
     }
     
     func spawnGroup(n int, f func(int)) chan struct{} {
        quit := make(chan struct{})
        job := make(chan int)
        var wg sync.WaitGroup
     
        for i := 0; i < n; i++ {
           wg.Add(1)
           go func(i int) {
              defer wg.Done() // 保证wg.Done在goroutine退出前被执行
              name := fmt.Sprintf("worker-%d:", i)
              for {
                 j, ok := <-job
                 if !ok {
                    println(name, "done")
                    return
                 }
                 // do the job
                 f(j)
              }
           }(i)
        }
     
        go func() {
           <-quit
           close(job) // 广播给所有新goroutine
           wg.Wait()
           quit <- struct{}{}
        }()
     
        return quit
     }
     
     func main() {
        quit := spawnGroup(5, worker)
        println("spawn a group of workers")
     
        time.Sleep(5 * time.Second)
        // notify the worker goroutine group to exit
        println("notify the worker group to exit...")
        quit <- struct{}{}
     
        timer := time.NewTimer(time.Second * 5)
        defer timer.Stop()
        select {
        case <-timer.C:
           println("wait group workers exit timeout!")
        case <-quit:
           println("group workers done")
        }
     }
     ```

4. 退出模式的应用

   - 并行退出

     ```Go
     type GracefullyShutdowner interface {
        Shutdown(waitTimeout time.Duration) error
     }
     
     type ShutdownerFunc func(time.Duration) error
     
     func (f ShutdownerFunc) Shutdown(waitTimeout time.Duration) error {
        return f(waitTimeout)
     }
     
     func ConcurrentShutdown(waitTimeout time.Duration, shutdowners ...GracefullyShutdowner) error {
        c := make(chan struct{})
     
        go func() {
           var wg sync.WaitGroup
           for _, g := range shutdowners {
              wg.Add(1)
              go func(shutdowner GracefullyShutdowner) {
                 defer wg.Done()
                 shutdowner.Shutdown(waitTimeout)
              }(g)
           }
           wg.Wait()
           c <- struct{}{}
        }()
     
        timer := time.NewTimer(waitTimeout)
        defer timer.Stop()
     
        select {
        case <-c:
           return nil
        case <-timer.C:
           return errors.New("wait timeout")
        }
     }
     ```

   - 串行退出

     ```Go
     func SequentialShutdown(waitTimeout time.Duration, shutdowners ...GracefullyShutdowner) error {
        start := time.Now()
        var left time.Duration
        timer := time.NewTimer(waitTimeout)
     
        for _, g := range shutdowners {
           elapsed := time.Since(start)
           left = waitTimeout - elapsed
     
           c := make(chan struct{})
           go func(shutdowner GracefullyShutdowner) {
              shutdowner.Shutdown(left)
              c <- struct{}{}
           }(g)
     
           timer.Reset(left)
           select {
           case <-c:
              //continue
           case <-timer.C:
              return errors.New("wait timeout")
           }
        }
     
        return nil
     }
     ```

### 管道模式

由 channel 连接的一条“数据流水线”。在该流水线中，每个数据处理环节都由**一组功能相同的 goroutine** 完成。在每个数据处理环节，goroutine 都要从数据输入 channel 获取前一个环节生产的数据，然后对这些数据进行处理，并将处理后的结果数据通过数据输出 channel 发往下一个环节。管道模式具有良好的**可扩展性**。两种基于管道模式的**扩展模式**。

- 扇出模式：在某个处理环节，过个功能相同的 goroutine 从同一个 channel 读取数据并处理，直到该 channel 关闭，这种情况被称为“扇出”（fan-out）。使用扇出模式可以在一组 goroutine 中均衡分配工作量，从而更均衡地利用 CPU。
- 扇入模式：在某个处理环节，处理程序面对不止一个输入 goroutine，我们把所有输入 channel 的数据汇聚到一个统一的输入 channel，然后处理程序再从这个 channel 中读取数据并处理，直到该 channel 因所有输入 channel 关闭而关闭。这种情况被称为“扇入”（fan-in）。

```Go
func newNumGenerator(start, count int) <-chan int {
   c := make(chan int)
   go func() {
      for i := start; i < start+count; i++ {
         c <- i
      }
      close(c)
   }()
   return c
}

func filterOdd(in int) (int, bool) {
   if in%2 != 0 {
      return 0, false
   }
   return in, true
}

func square(in int) (int, bool) {
   return in * in, true
}

func spawnGroup(name string, num int, f func(int) (int, bool), in <-chan int) <-chan int {
   groupOut := make(chan int)
   var outSlice []chan int
   for i := 0; i < num; i++ {
      out := make(chan int)
      go func(i int) {
         name := fmt.Sprintf("%s-%d:", name, i)
         fmt.Printf("%s begin to work...\n", name)

         for v := range in {
            r, ok := f(v)
            if ok {
               out <- r
            }
         }
         close(out)
         fmt.Printf("%s work done\n", name)
      }(i)
      outSlice = append(outSlice, out)
   }

   // Fan-in
   //
   // out --\
   //        \
   // out ---- --> groupOut
   //        /
   // out --/
   //
   go func() {
      var wg sync.WaitGroup
      for _, out := range outSlice {
         wg.Add(1)
         go func(out <-chan int) {
            for v := range out {
               groupOut <- v
            }
            wg.Done()
         }(out)
      }
      wg.Wait()
      close(groupOut)
   }()

   return groupOut
}

func main() {
   in := newNumGenerator(1, 20)
   out := spawnGroup("square", 2, square, spawnGroup("filterOdd", 3, filterOdd, in))

   time.Sleep(3 * time.Second)

   for v := range out {
      fmt.Println(v)
   }
}
```

### 超时与取消模式

```Go
type result struct {
   value string
}

func first(servers ...*httptest.Server) (result, error) {
   c := make(chan result)
   ctx, cancel := context.WithCancel(context.Background())
   defer cancel()
   queryFunc := func(i int, server *httptest.Server) {
      url := server.URL
      req, err := http.NewRequest("GET", url, nil)
      if err != nil {
         log.Printf("query goroutine-%d: http NewRequest error: %s\n", i, err)
         return
      }
      req = req.WithContext(ctx)

      log.Printf("query goroutine-%d: send request...\n", i)
      resp, err := http.DefaultClient.Do(req)
      if err != nil {
         log.Printf("query goroutine-%d: get return error: %s\n", i, err)
         return
      }
      log.Printf("query goroutine-%d: get response\n", i)
      defer resp.Body.Close()
      body, _ := ioutil.ReadAll(resp.Body)

      c <- result{
         value: string(body),
      }
      return
   }

   for i, serv := range servers {
      go queryFunc(i, serv)
   }

   select {
   case r := <-c:
      return r, nil
   case <-time.After(500 * time.Millisecond):
      return result{}, errors.New("timeout")
   }
}

func fakeWeatherServer(name string, interval int) *httptest.Server {
   return httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
      log.Printf("%s receive a http request\n", name)
      time.Sleep(time.Duration(interval) * time.Millisecond)
      w.Write([]byte(name + ":ok"))
   }))
}

func main() {
   result, err := first(fakeWeatherServer("open-weather-1", 200),
      fakeWeatherServer("open-weather-2", 1000),
      fakeWeatherServer("open-weather-3", 600))
   if err != nil {
      log.Println("invoke first error:", err)
      return
   }

   fmt.Println(result)
   time.Sleep(2 * time.Second)
}
```

## 34 了解 channel 的妙用

### 无缓冲 channel

无缓冲 channel 兼具通信和同步特性。可以通过不带有 capacity 参数的内置 make 函数创建一个可用的无缓冲 channel：`c := make(chan T)`。由于无缓冲 channel 的运行时层实现不带有缓冲区，因此对无缓冲 channel 的接收和发送操作是同步的，即对于同一个无缓冲 channel，只有在其进行接受操作的 goroutine 和对其进行发送操作的 goroutine 都存在的情况下，通信才能进行，否则单方面的操作会让对应的 goroutine 陷入阻塞状态。发送动作一定发生在接收动作完成之前；接收动作一定发生在发送动作之前。

1. [用作信号传递](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-1.go)
   - [一对一通知信号](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-2.go)；
   - [一对多通知信号](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-3.go)；[一对多广播机制](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-4.go)；
2. [用于替代锁机制](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-6.go)；（[锁机制](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-5.go)）；

### 带缓冲 channel

带缓冲的 channel 可以通过带有 capacity 参数的内置 make 函数创建：`c := make(chan T, capacity)`。由于带缓冲channel 的运行时层实现带有缓冲区，因此对带缓冲 channel 的发送操作在缓冲区未满、接收操作在缓冲区非空的情况下是**异步**的（发送或接收无须阻塞等待）。也就是说，对一个带缓冲 channel，在缓冲区无数据或有数据但未满的情况下，对其进行发送操作的 goroutine 不会阻塞；在缓冲区已满的情况下，对其进行发送操作的 goroutine 会阻塞；在缓冲区为空的情况下，对其进行接收操作的 goroutine 亦会阻塞。

1. [用作消息队列](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/tree/main/chapter6/sources/go-channel-operation-benchmark)：无论是单收单发还是多收多发，带缓冲 channel 的收发性能都要好于无缓冲 channel；对于带缓冲 channel 而言，选择适当容量会在一定程度上提升收发性能。
2. [用作计数信号量](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-7.go)
3. [len(channel) 的应用](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-8.go)：**多发送单接收**的场景，我们可以在接收者 goroutine 中根据 len(channel) 是否大于 0 来判断 channel 中是否有数据需要接收。**多接收单发送**的场景，我们可以在发送者 goroutine 中根据 len(channel) 是否小于 cap(channel) 来判断是否可以执行向 channel 的发送操作。一旦多个 goroutine 共同对 channel 进行收发操作，那么 len(channel) 就会在多个 goroutine 间形成竞态，单纯依靠 len(channel) 中元素的状态，不能保证在后续对 channel 进行收发时 channel 的状态不变。常见的方法是将判空与读取放在一个事务中，将判满与写入放在一个事务中，而这类事务我们可以通过 select 实现。
   - 无缓冲 channel，len(channel) 总是返回 0；
   - 带缓冲 channel，len(channel) 返回当前 channel 中尚未被读取的元素个数；

### nil channel 的妙用

[一个已关闭的 channel 接收数据将永远不会被阻塞](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-9.go)。

[对没有初始化的 channel (nil channel) 进行读写操作将会发生阻塞](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-channel-case-10.go)。

因此，已经被置为 nil 的 c1 或 c2 的分支将再也不会被 select 选中执行。

### 与 select 结合使用的一些惯用法

1. 利用 default 分支避免阻塞；
2. 实现超时机制：`<-time.After(time.Second)`； 
3. 实现心跳机制：`heartbeat := time.NewTicker(time.Second)`，`select { case <- heartbeat.C: ... }`；

## 35 了解 sync 包的正确用法

Go 语言在提供 CSP 并发模型原语的同时，还通过标准库的 **sync 包**提供了针对传统基于**共享内存并发模型**的基本同步原语，包括互斥锁（sync.Mutex）、读写锁（sync.RWMutex）、条件变量（sync.Cond）等。

### sync 包还是 channel

1. [需要高性能的临界区同步机制](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-1_test.go)场景：sync.Mutex 实现的同步机制的性能要比 channel 实现的高出大约 3 倍；
2. 不想转移结构体对象所有权，但又要保证结构体内部状态数据能在多个 goroutine 之间同步访问；

### 使用 sync 包的注意事项

**sync 包中定义的结构类型首次使用后不应对其进行复制操作**。

Go 标准库中 sync.Mutex 的定义如下：

```Go
type Mutex struct {
	state int32  // 表示当前互斥锁的状态
	sema  uint32 // 用于控制锁状态的信号量
}
```

[示例：复制首次使用后的 Mutex](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-2.go)。对 Mutex 实例的复制即是对两个整型字段的复制。在初始状态下，Mutex 实例处于 **Unlocked** 状态（state 和 sema 均为 0）。复制处于初始状态的 Mutex 实例，副本的 state 和 sema 均为 0，这与自定义一个新的 Mutex 实例无异。而当调用了 Lock 方法后，Mutex 实例变为 Locked 状态（state 字段值为 sync.mutex-Locked），此时复制处于 Locked 状态的 Mutex 实例，再对其实例副本调用 Lock 方法将会导致其进入阻塞状态（死锁）。

因此，在使用 sync 包中类型时，推荐使用**闭包**方式或**传递类型实例**（**或包裹该类型的类型实例**）**的地址或指针**的方式进行。

### 互斥锁还是读写锁

互斥锁是临界区同步原语的**首选**，它常被用来对结构体对象的内部状态、缓存等进行保护，是使用最为广泛的临界区同步原语。

[示例：互斥锁 vs 读写锁](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-3_test.go)。读写锁适合应用在**具有一定并发量且读多写少**的场合。在有大量并发读的情况下，多个 goroutine 可以同时持有读锁，从而减少在锁竞争中等待的时间；而互斥锁即便是读请求，同一时刻也只能有一个 goroutine 持有锁，其他 goroutine 只能阻塞在加锁操作上等待被调度。

### 条件变量

一个条件变量可以理解为一个容器，这个容器中存放着一个或一组等待着某个条件成立的 goroutine。当条件成立时，这些处于等待状态的 goroutine 将得到通知并被唤醒以继续后续的工作。

[示例：连续轮询](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-4.go)。如果没有条件变量，开发人员可能需要在 goroutine 中通过连续轮询的方式检查是否满足条件。连续轮询非常消耗资源，因为 goroutine 在这个过程中处于活动状态但其工作并无进展。

[示例：条件变量](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-5.go)。sync.Cond 实例的初始化需要一个满足实现了 sync.Locker 接口的类型实例，通常我们使用 sync.Mutex。条件变量需要这个互斥锁来同步临界区，保护用作条件的数据。Wait 方法在 goroutine 挂起前会进行 Unlock 操作。在调用 BroadCast 方法后，各个阻塞的 goroutine 将被唤醒并从 Wait 方法中返回。在 Wait 方法返回前，Wait 方法会再次加锁让 goroutine 进入临界区。

### 使用 sync.Once 实现单例模式

sync.Once 可以保证**任意一个函数**在程序运行期间只被执行一次，它的“仅执行一次”语义被一些包用于初始化和资源清理的过程中，以避免重复执行初始化或资源关闭操作。

[示例：单例模式](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-sync-package-6.go)。

- once.Do 会等待 f 执行完毕后才返回，这期间其他执行 once.Do 函数的 goroutine 将会阻塞等待；
- Do 函数返回后，后续的 goroutine 再执行 Do 函数将不再执行 f 并立即返回；
- 即便在函数 f 中出现 panic，sync.Once原语也会认为 once.Do 执行完毕，后续对 once.Do 的调用将不再执行 f；

### 使用 sync.Pool 减轻垃圾回收压力

sync.Pool 是一个数据对象储存池，它具有如下特点：

- goroutine 并发安全，可以被多个 goroutine 同时使用；
- 放入该缓存池中的数据对象的生命是暂时的，随时都可能被垃圾回收掉；
- 缓存池中的数据对象是可以重复利用的，这样可以在一定程度上降低数据对象重新分配的频度，减轻 GC 的压力；
- sync.Pool 为每个 P 单独建立一个 local 缓存池，进一步降低高并发下对锁的争抢；

通过 sync.Pool 来复用数据对象的方式可以有效降低内存分配频率，减轻垃圾回收压力，从而提高处理性能。sync.Pool 的一个典型应用就是建立像 bytes.Buffer 这样类型的临时缓存对象池：

```Go
var bufPool = sync.Pool {
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}
```

Go 标准库采用两种方式来缓解 sync.Pool 带来的内存消耗负担：

- 限制要放回缓存池中的数据对象大小；
- 建立多级缓存池；

## 36 使用 atomic 包实现伸缩性更好的并发读取

atomic 包提供了两大类原子操作接口：

1. 针对整型变量的，包括有符号整型、无符号整型以及对应的指针类型；
2. 针对自定义类型；

[示例：对共享整型变量的无锁读写](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-atomic-package-1_test.go)。利用原子操作的无锁并发写的性能随着并发量增大几乎保持恒定；利用原子操作的无锁并发读的性能随着并发量增大有持续提升的趋势，并且性能约为读锁的 200 倍。

[示例：对共享自定义类型变量的无锁读写](https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster/blob/main/chapter6/sources/go-atomic-package-2_test.go)。利用原子操作的无锁并发写的性能随着并发量增大而小幅下降；利用原子操作的无锁并发读的性能随着并发量增大有持续提升的趋势，并且性能约为读锁的 200 倍。

小结：

- 随着并发量提升，使用 atomic 实现的**共享变量**的并发读写性能表现更为稳定，尤其是原子读操作，这让 atomic 与 sync 包中的原语比起来表现出更好的伸缩性和更高的性能。由此可以看出 atomic 包更适合**一些对性能十分敏感、并发量较大且读多写少**的场合。
- 但 atomic 原子操作可以用来同步的范围有较大限制，仅是一个整型变量或自定义类型变量。如果要对一个复杂的临界区数据进行同步，那么首选依旧是 sync 包中的原语。

## 参考

《Go 语言精进之路：从新手到高手的编程思想、方法和技巧》——白明